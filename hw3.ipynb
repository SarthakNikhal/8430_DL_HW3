{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d94b2a-f477-410d-a10a-260e4b680138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30936d64-e040-436b-95a4-aeb41539aa55",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6125f97-adc8-4a5f-b09e-866fe3274e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da1cd49-a3da-4234-bd31-d51109e6d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/sarthan/.local/lib/python3.9/site-packages (4.39.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: requests in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/sarthan/.local/lib/python3.9/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sarthan/.local/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/sarthan/.local/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sarthan/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sarthan/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c43aab-2972-4898-b79c-a9d471b24597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.is_available()\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1374299-f4b8-4e8c-beb6-bf264c22ae55",
   "metadata": {},
   "source": [
    "#### Extracting data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b34d10-f031-4046-992f-6fdff5938b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def get_data(path): \n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_q = 0\n",
    "    num_pos = 0\n",
    "    num_imp = 0\n",
    "\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                num_q  = num_q  +1\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "    return num_q, num_pos, num_imp, contexts, questions, answers\n",
    "\n",
    "\n",
    "num_q, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('spoken_train-v1.1.json')\n",
    "num_questions  = num_q\n",
    "num_posible = num_pos\n",
    "num_imposible  = num_imp\n",
    "\n",
    "\n",
    "num_q, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('spoken_test-v1.1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352d84c-db3a-4755-b9ee-cee8e4053f24",
   "metadata": {},
   "source": [
    "#### Adding extra field to mark text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b19ce32-f6d1-46dd-ae5d-b7195e49986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_answer_end(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "add_answer_end(train_answers, train_contexts)\n",
    "add_answer_end(valid_answers, valid_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cfe83-3cba-49c7-9c7a-a4181c4ea5cf",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83625053-cf5b-4640-9eee-e1042835b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"bert-base-uncased\"\n",
    "\n",
    "doc_stride = 128\n",
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "pad_on_right = tokenizerFast.padding_side == \"right\"\n",
    "train_contexts_trunc=[]\n",
    "\n",
    "for i in range(len(train_contexts)):\n",
    "    if(len(train_contexts[i])>512):\n",
    "        answer_start=train_answers[i]['answer_start']\n",
    "        answer_end=train_answers[i]['answer_start']+len(train_answers[i]['text'])\n",
    "        mid=(answer_start+answer_end)//2\n",
    "        para_start=max(0,min(mid - MAX_LENGTH//2,len(train_contexts[i])-MAX_LENGTH))\n",
    "        para_end = para_start + MAX_LENGTH \n",
    "        train_contexts_trunc.append(train_contexts[i][para_start:para_end])\n",
    "        train_answers[i]['answer_start']=((512/2)-len(train_answers[i])//2)\n",
    "    else:\n",
    "        train_contexts_trunc.append(train_contexts[i])\n",
    "\n",
    "train_encodings_fast = tokenizerFast(train_questions, train_contexts_trunc,  max_length = MAX_LENGTH,truncation=True,\n",
    "        stride=doc_stride,\n",
    "        padding=True)\n",
    "valid_encodings_fast = tokenizerFast(valid_questions,valid_contexts,  max_length = MAX_LENGTH, truncation=True,stride=doc_stride,\n",
    "        padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee0ca1-d442-4682-973c-988d6a4ff4d6",
   "metadata": {},
   "source": [
    "#### Finding start and end of answer in paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2539a116-f00e-443a-b5f4-b2306f6a09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_Answer_start_and_end_train(idx):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                ret_start = a+1\n",
    "                ret_end = a+i+1\n",
    "                break\n",
    "    return(ret_start, ret_end)\n",
    "\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h in range(len(train_encodings_fast['input_ids'])):\n",
    "    s, e = ret_Answer_start_and_end_train(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    if s==0:\n",
    "        ctr = ctr + 1\n",
    "\n",
    "train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "valid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9100dd-8356-4fde-8769-8c3f3787d741",
   "metadata": {},
   "source": [
    "#### Creating dataset for loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71c2835-2177-4f93-acfa-193977932ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "train_dataset = InputDataset(train_encodings_fast)\n",
    "valid_dataset = InputDataset(valid_encodings_fast)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "bert_model = BertModel.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38f02b-29d8-462a-b897-6118f2ccd45b",
   "metadata": {},
   "source": [
    "#### Defining model for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cf0d62-2ba2-4405-bb59-710825f31707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l1 = nn.Linear(768 * 2, 768 * 2)\n",
    "        self.l2 = nn.Linear(768 * 2, 2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            self.drop_out,\n",
    "            self.l1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.l2 \n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output[2]\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)\n",
    "        logits = self.linear_relu_stack(out)\n",
    "        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits\n",
    "\n",
    "model = QAModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c820489-4114-44dd-a8bd-cc424f622055",
   "metadata": {},
   "source": [
    "#### Loss and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd346b9-0480-404d-881e-65b01b68eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthan/.local/lib/python3.9/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    probs_start = smax(start_logits)\n",
    "    inv_probs_start = 1 - probs_start\n",
    "    probs_end = smax(end_logits)\n",
    "    inv_probs_end = 1 - probs_end\n",
    "    \n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    log_probs_start = lsmax(start_logits)\n",
    "    log_probs_end = lsmax(end_logits)\n",
    "    \n",
    "    nll = nn.NLLLoss()\n",
    "    \n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_positions)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_positions)\n",
    "    \n",
    "    return ((fl_start + fl_end)/2)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "total_acc = []\n",
    "total_loss = []\n",
    "\n",
    "def train_epoch(model, dataloader, epoch):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    batch_tracker = 0\n",
    "    for batch in tqdm(dataloader, desc = 'Running Epoch '):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        out_start, out_end = model(input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "\n",
    "        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions,1)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        start_pred = torch.argmax(out_start, dim=1)\n",
    "        end_pred = torch.argmax(out_end, dim=1)\n",
    "            \n",
    "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
    "\n",
    "        batch_tracker = batch_tracker + 1\n",
    "        if batch_tracker==250 and epoch==1:\n",
    "            total_acc.append(sum(acc)/len(acc))\n",
    "            loss_avg = sum(losses)/len(losses)\n",
    "            total_loss.append(loss_avg)\n",
    "            batch_tracker = 0\n",
    "    ret_acc = sum(acc)/len(acc)\n",
    "    ret_loss = sum(losses)/len(losses)\n",
    "    \n",
    "    num_same = (start_pred == start_positions).sum() + (end_pred == end_positions).sum()\n",
    "    precision = 1.0 * num_same / (len(start_pred) + len(end_pred))\n",
    "    recall = 1.0 * num_same / (len(start_positions) + len(end_positions))\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    return (ret_acc, ret_loss, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c466443-1113-4117-be61-4a2167ad96b6",
   "metadata": {},
   "source": [
    "#### Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5822723-1cb1-4eb2-970e-89c316d5c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    answer_list=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "\n",
    "            start_pred = torch.argmax(out_start)\n",
    "            end_pred = torch.argmax(out_end)\n",
    "            answer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_pred:end_pred]))\n",
    "            tanswer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_true[0]:end_true[0]]))\n",
    "            answer_list.append([answer,tanswer])\n",
    "\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81fea28-2a78-4893-b1da-3019e020dfdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in /home/sarthan/.local/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: packaging in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from evaluate) (1.21.5)\n",
      "Requirement already satisfied: xxhash in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: pandas in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from evaluate) (1.4.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: multiprocess in /home/sarthan/.local/lib/python3.9/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/sarthan/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: filelock in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/sarthan/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/sarthan/.local/lib/python3.9/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->datasets>=2.0.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from packaging->evaluate) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5890d-d6bd-48ed-9c63-d842d906be26",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6baab97e-34a1-410a-be53-1eba3b6cd8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting taining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 2320/2320 [05:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47150746614768585\n",
      "Loss: 1.7638644711467726\n",
      "F1: 0.4285714626312256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:21<00:00, 78.79it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [05:15<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6645493380596925\n",
      "Loss: 0.8845053916604354\n",
      "F1: 0.2857142984867096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:21<00:00, 78.96it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [05:15<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7745131619531532\n",
      "Loss: 0.5268415865697095\n",
      "F1: 0.714285671710968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:21<00:00, 78.95it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [05:15<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8462111299407893\n",
      "Loss: 0.3208409930474992\n",
      "F1: 0.9285714626312256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:30<00:00, 75.38it/s] \n",
      "Running Epoch : 100%|██████████| 2320/2320 [05:15<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8931130695959617\n",
      "Loss: 0.20511315739834038\n",
      "F1: 0.9285714626312256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:21<00:00, 78.93it/s]\n",
      "Running Epoch : 100%|██████████| 2320/2320 [05:15<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9237222906587452\n",
      "Loss: 0.14026409991387606\n",
      "F1: 0.785714328289032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:21<00:00, 78.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (base model) -  [4.934929133858268, 4.157165354330709, 4.0318740157480315, 4.102740157480315, 4.276094488188976, 4.551685039370079]\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "EPOCHS = 6\n",
    "model.to(device)\n",
    "wer_list=[]\n",
    "print('Starting taining')\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss, train_f1 = train_epoch(model, train_data_loader, epoch+1)\n",
    "    print(f\"Accuracy: {train_acc}\")\n",
    "    print(f\"Loss: {train_loss}\")\n",
    "    print(f\"F1: {train_f1}\")\n",
    "    \n",
    "    \n",
    "    answer_list = eval_model(model, valid_data_loader)\n",
    "    pred_answers=[]\n",
    "    true_answers=[]\n",
    "    for i in range(len(answer_list)):\n",
    "        if(len(answer_list[i][0])==0):\n",
    "            answer_list[i][0]=\"$\"\n",
    "        if(len(answer_list[i][1])==0):\n",
    "            answer_list[i][1]=\"$\"\n",
    "        pred_answers.append(answer_list[i][0])\n",
    "        true_answers.append(answer_list[i][1])\n",
    "    wer_score = wer.compute(predictions=pred_answers, references=true_answers)\n",
    "    wer_list.append(wer_score)\n",
    "\n",
    "print('WER (base model) - ',wer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf428088-e6a8-42ab-bf4a-c7dddc8de3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdce96-cdda-45aa-ad75-3a54df6700e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46192f6d-970b-4688-b960-f631903e154e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
